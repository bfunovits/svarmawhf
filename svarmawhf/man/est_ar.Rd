% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/zz_rldm_estimate_ar.R
\name{est_ar}
\alias{est_ar}
\alias{Yule-Walker}
\alias{Durbin-Levinson-Whittle}
\alias{est_ar_yw}
\alias{est_ar_dlw}
\alias{est_ar_ols}
\title{Estimate Autoregressive Models}
\usage{
est_ar(
  obj,
  p.max = NULL,
  penalty = NULL,
  ic = c("AIC", "BIC", "max"),
  method = c("yule-walker", "ols", "durbin-levinson-whittle"),
  mean_estimate = c("sample.mean", "intercept", "zero"),
  n.obs = NULL
)

est_ar_yw(gamma, p.max = (dim(gamma)[3] - 1), penalty = -1)

est_ar_dlw(gamma, p.max = (dim(gamma)[3] - 1), penalty = -1)

est_ar_ols(
  y,
  p.max = NULL,
  penalty = -1,
  mean_estimate = c("sample.mean", "intercept", "zero"),
  p.min = 0L
)
}
\arguments{
\item{obj}{either a "time series" object (i.e \code{as.matrix(obj)}
returns an \eqn{(N,m)}-dimensional numeric matrix)
or an \code{\link{autocov}} object which represents an (estimated) autocovariance function.
The type of the \code{autocov} object is irrelevant since \code{est_ar} always uses the
slot \code{obj$gamma} which contains the autocovariance function.}

\item{p.max}{(integer or \code{NULL}) Maximum order of the candidate AR models.
For the default choice see below.}

\item{penalty}{is a scalar (or NULL) which determines the "penalty" per parameter of the model.
Note that this parameter (if not \code{NULL}) overrides the paramater \code{ic}.}

\item{ic}{(character string) Which information criterion shall be used to find the optimal order.
Note that \code{ic="max"} means that an AR(p) model with \code{p=p.max} is estimated.
Default is \code{ic="AIC"}.}

\item{method}{Character string giving the method used to fit the model.
Note that 'yule-walker' and 'durbin-levinson-whittle' are (up to numerical errors) equivalent
and that the choice 'ols' is only available for a "time-series" object \code{obj}.}

\item{mean_estimate}{Character string giving the method used to estimate the mean \eqn{\mu}.
Default is \code{mean_estimate = "sample.mean"}.
See the details below.}

\item{n.obs}{Optional integer which gives the sample size \eqn{N}.
This parameter is only used, when \code{obj} is an \code{autocov} object.
If \code{n.obs=NULL} then the slot \code{obj$n.obs} is used.
Note that \code{obj$n.obs=NULL} or \code{obj$n.obs=Inf} refers to the case of a population
autocovariance function, i.e. \eqn{N=\infty}.
\cr
For a "time series" object the sample size is of course set to the number of observations,
i.e. \code{n.obs = nrow(as.matrix(obj))}.
\cr
The sample size \eqn{N} controls the computation of the default maximum order \code{p.max} and
the computation of the information criterion.}

\item{gamma}{\eqn{(m,m,lag.max+1)}-dimensional array, which contains the (sample) autocovariance function.}

\item{y}{\eqn{(N,m)}-dimensional matrix, which contains the sample.}

\item{p.min}{(non negative integer) Minimum order of the candidate AR models.
Only used by \code{est_ar_ols}.}
}
\value{
The function \code{est_ar} returns a list with components
    \item{model}{\code{\link{armamod}} object which represents the estimated AR model.}
    \item{p}{optimal model order.}
    \item{stats}{(p.max+1,4) dimensional matrix which stores the \eqn{\ln\det(\Sigma_p)}{ln det (\Sigma[p])}
                  values, the number of parameters and the IC values. See the details below.}
    \item{y.mean}{estimate of the mean \eqn{\mu}.}
    \item{ll}{The log likelihood of the estimated model.}
The "helper" functions \code{est_ar_yw}, \code{est_ar_dlw} and \code{est_ar_ols} return a list with components
    \item{a}{\code{(m,m,p)}-dimensional array with the estimated AR coefficients \eqn{a_i}{a[i]}.}
    \item{sigma}{\code{(m,m)}-dimensional matrix with the estimated noise covariance \eqn{\Sigma}.}
    \item{p}{estimate of the AR order.}
    \item{stats}{(p.max+1,4) dimensional matrix which stores the \eqn{\ln\det(\Sigma_p)}{ln det (\Sigma[p])}
                  values, the number of parameters and the IC values. See the details below.}
    \item{y.mean}{(\code{est_ar_ols} only) estimate of the mean \eqn{\mu}.}
    \item{residuals}{(\code{est_ar_ols} only) \code{(n.obs,m)} dimensional matrix with the OLS residuals.}
    \item{partial}{(\code{est_ar_dlw} only) \code{(m,m,p.max+1)} dimensional array with
                   the (estimated) partial autocorrelation coefficients.}
}
\description{
This function was originally part of R package \strong{RLDM}.
\cr
The function \code{est_ar} estimates (V)AR models
\deqn{(y_t - \mu) = a_1 (y_{t-1} - \mu) + \cdots + a_p (y_{t-p} - \mu) + u_t}{
       (y[t] - \mu) = a[1] (y[t-1] - \mu) + ... + a[p] (y[t-p] - \mu) + u[t]}
from a given sample or a given (sample) autocovariance function.
The model order \eqn{p} is chosen by an information criterion, like \emph{AIC} or \emph{BIC}.
The "helper" functions \code{est_ar_ols}, \code{est_ar_yw} and \code{est_ar_dlw} implement
the three available estimation methods: estimation by ordinary least squares, the Yule-Walker
estimates and the Durbin-Levinson-Whittle method.
}
\section{OLS method}{


The helper function \code{est_ar_ols} implements three schemes to estimate the mean \eqn{\mu}
and the AR parameters. The choice \code{mean_estimate = "zero"} assumes \eqn{\mu=0} and thus
the AR parameters are determined from the regression:
\deqn{y_t = a_1 y_{t-1} + \cdots + a_p y_{t-p} + u_t \mbox{ for } t=p+1,\ldots,N}{
      y[t] = a[1] y[t-1] + ... + a[p] y[t-p] + u[t] for t=p+1,...,N}
In the case \code{mean_estimate = "sample.mean"} the mean \eqn{\mu} is estimated by the sample
mean and the AR parameters are determined by the LS estimate of the regression
\deqn{(y_t - \mu) = a_1 (y_{t-1} - \mu) + \cdots + a_p (y_{t-p} - \mu) + u_t \mbox{ for } t=p+1,\ldots,N}{
      (y[t] - \mu) = a[1] (y[t-1] - \mu) + ... + a[p] (y[t-p] - \mu) + u[t] for t=p+1,...,N}
In the last case \code{mean_estimate = "intercept"}, a regression with intercept
\deqn{y_t = d + a_1 y_{t-1} + \cdots + a_p y_{t-p} + u_t \mbox{ for } t=p+1,\ldots,N}{
      y[t] = d + a[1] y[t-1] + ... + a[p] y[t-p] + u[t] for t=p+1,...,N}
is considered. The estimate for \eqn{\mu} then is obtained as
\deqn{\mu = (I_m - a_1 - \cdots - a_p)^{-1} d}{
      \mu = (I - a[1] - ... - a[p])^{-1} d}
This estimate of the mean \eqn{\mu} fails if the estimated AR model has a \emph{unit root}, i.e. if
\eqn{(I_m - a_1 - \cdots - a_p)}{(I - a[1] - ... - a[p])} is singular.

The sample covariance of the corresponding residuals (scaled with \eqn{1/(N-p)}) serves as
an estimate for the noise covariance \eqn{\Sigma}.

For the actual computations the routine \code{\link[stats]{lsfit}} in the \pkg{stats} package is used.
}

\section{Yule-Walker estimates}{


Both  \code{est_ar_yw} and \code{est_ar_dlw} use the \emph{Yule-Walker} equations to estimate
the AR coefficients \eqn{(a_i)}{(a[i])} and the noise covariance matrix \eqn{\Sigma}.
However, they use a different numerical scheme to solve these equations.
The function \code{est_ar_dlw} uses the \emph{Durbin-Levinson-Whittle} recursions and
in addition returns (estimates of) the partial autocorrelation coefficients.

If \code{obj} is a "time series" object, then first the ACF is estimated with a call to
\code{\link{autocov}}. The option \code{mean_estimate = "zero"} implies that the mean is assumed to
be zero (\eqn{\mu = 0}) and therefore \code{autocov} is called with the option \code{demean = FALSE}.

For \code{mean_estimate = "sample.mean"} or \code{mean_estimate = "intercept"} the mean \eqn{\mu}
is estimated by the sample mean and the ACF is computed with  \code{demean = TRUE}.
}

\section{Estimation of the AR order}{


The order \eqn{p} of the AR model is chosen by minimizing an information criterion of the form
\deqn{IC(p) = \ln\det\Sigma_p + c(p)r(N) \mbox{ for } p = 0,\ldots,p_{\max}}{
      IC(p) = ln(det(\Sigma[p])) + c(p)r(N) for p = 0,...,p.max}
where \eqn{\Sigma_p}{\Sigma[p]} is the estimate of the noise (innovation) covariance,
\eqn{c(p)} counts the number of parameters of the model,
and \eqn{r(N)} is the "penalty" per parameter of the model.
Note that \eqn{\log\det\Sigma}{log(det(\Sigma))} is up to a constant
and a scaling factor \eqn{-(N-p)/2}
equal to the (scaled, approximate) Gaussian log likelihood of the model
\deqn{ll = -(1/2)(m \ln(2\pi) + m + \ln\det \Sigma_p)}{
      ll = -(1/2)(m ln(2\pi) + m + ln(det(\Sigma[p])))}
See also \code{\link{ll}}. Note that the value \eqn{ll}, which is returned by
this routine, is the (approximate) log Likelihood **scaled** by a factor \eqn{1/(N-p)}.

For an AR(p) model with intercept, the number of parameters is
\eqn{c(p) = p m^2 + m}{c(p) = p*m^2 + m} and for the AR model without intercept
\eqn{c(p) = p m^2}{c(p) = p*m^2}.

The Akaike information criterion (AIC) corresponds to \eqn{r(N)=2/N} and the
Bayes information criterion (BIC) uses the penatlty \eqn{r(N)=\log(N)/N}{r(N)=log(N)/N}.

For the helper routines, the user has to set the penalty term \eqn{r(N)} explicitly via the
input parameter "\code{penalty}". The default choice \code{penalty = -1} means that the maximum
possible order \code{p=p.max} is chosen.

The function \code{est_ar} offers the parameter "\code{ic}" which tells the routine to set the
penalty accordingly. Note that the choice \code{ic="max"} sets \eqn{r(N) = -1} and thus again
the model with maximum possible order is fitted.

The default maximum order \code{p.max} is chosen as follows.
The helper functions \code{est_ar_yw} and \code{est_ar_dlw} simply chose the maximum
accordng to maximum lag of the given autocovariances, \code{p.max = dim(gamma)[3] - 1}.
The routine \code{est_ar_ols} uses the minimum of \eqn{12}, \eqn{(N-1)/(m+1)} and \eqn{10*log10(N)}
as default. The function \code{est_ar} uses the same value.
However, if "\code{obj}" is an \code{autocov} object then \code{p.max} is in addition bounded
by the number of lags contained in this object.
}

\section{Notes}{


The Yule-Walker estimates offer an easy way to reconstruct the "true" model if the population
autocovariance function is given. The noise covariance (and thus the likelihood values) should
not improve when a model with an order larger than the true model order is "estimated".
However due to numerical errors this may not be true. As a simple trick one may call \code{est_ar}
(\code{est_ar_yw} or \code{est_ar_dlw}) with a very small positive \code{penalty}. See the example below.

The functions are essentially equivalent to the \pkg{stats} routines.
They are (re) implemented for convenience, such that the input and output parameters (models) fit
to the \pkg{RLDM} conventions.

The AIC values of \pkg{RLDM} routines are equivalent to the AIC values computed
by the \pkg{stats} routines up to a constant and up to scaling by \eqn{N}.

It seems that the Yule-Walker estimate \code{stats::\link[stats]{ar.yw}} uses a scaling
factor \eqn{(N - m(p+1))/N} for the noise covariance \eqn{\Sigma}.

Finally note that \code{est_ar_ols}, \code{est_ar_yw} and \code{est_ar_dlw} are mainly
intended as "internal helper" functions.
Therefore, these functions do not check the validity of the input parameters.
}

